{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformer import Transformer\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from accuracy import sequence_level_accuracy, token_lvl_accuracy\n",
    "\n",
    "# %%\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Running on {device}\")\n",
    "\n",
    "# Experiment 2 & 3 Hyperparameters\n",
    "EMB_DIM = 128\n",
    "N_LAYERS = 2\n",
    "N_HEADS = 8\n",
    "FORWARD_DIM = 256\n",
    "DROPOUT = 0.15\n",
    "LEARNING_RATE = 2e-4\n",
    "GRAD_CLIP = 1\n",
    "BATCH_SIZE = 16\n",
    "MAX_LEN = 128\n",
    "# Optimizer: AdamW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TasksData(Dataset):\n",
    "    def __init__(self, data_dir, file, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.file = file\n",
    "        text_file = os.path.join(data_dir, file)\n",
    "\n",
    "        data_dict = {\"src\": [], \"tgt\": []}\n",
    "\n",
    "        with open(text_file, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            for line in lines:\n",
    "                src = line.split('OUT:')[0]\n",
    "                src = src.split('IN:')[1].strip()\n",
    "                tgt = line.split('OUT:')[1].strip()\n",
    "\n",
    "                data_dict['src'].append(src)\n",
    "                data_dict['tgt'].append(tgt)\n",
    "\n",
    "        self.data = pd.DataFrame(data_dict)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        src = self.data['src'].iloc[idx] + ' <EOS>'\n",
    "        tgt = '<SOS> ' + self.data['tgt'].iloc[idx] + ' <EOS>'\n",
    "        return src, tgt\n",
    "\n",
    "def create_vocab(dataset):\n",
    "    vocab = set()\n",
    "\n",
    "    for sample in dataset:\n",
    "        vocab.update(sample.split())\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training, saving, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/916 [00:00<?, ?it/s]c:\\Users\\magnu\\UCPH\\9-Semester\\Advanced-Topics-in-Natural-Language-Processing\\crispy-fortnight\\transformer.py:187: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\TensorShape.cpp:3701.)\n",
      "  K_transposed = K.T.permute(3, 1, 0, 2)\n",
      "Exp 32, Epoch [1/10], Loss: 0.5159: 100%|██████████| 916/916 [00:17<00:00, 51.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exp 32, Epoch [1/10], Loss: 0.7516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exp 32, Epoch [2/10], Loss: 0.4042: 100%|██████████| 916/916 [00:18<00:00, 49.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exp 32, Epoch [2/10], Loss: 0.4412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exp 32, Epoch [3/10], Loss: 0.2385: 100%|██████████| 916/916 [00:18<00:00, 48.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exp 32, Epoch [3/10], Loss: 0.3537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exp 32, Epoch [4/10], Loss: 0.2440: 100%|██████████| 916/916 [00:20<00:00, 45.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exp 32, Epoch [4/10], Loss: 0.2563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exp 32, Epoch [5/10], Loss: 0.1612: 100%|██████████| 916/916 [00:19<00:00, 46.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exp 32, Epoch [5/10], Loss: 0.1494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exp 32, Epoch [6/10], Loss: 0.0886: 100%|██████████| 916/916 [00:18<00:00, 48.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exp 32, Epoch [6/10], Loss: 0.1055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exp 32, Epoch [7/10], Loss: 0.0528: 100%|██████████| 916/916 [00:17<00:00, 52.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exp 32, Epoch [7/10], Loss: 0.0827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exp 32, Epoch [8/10], Loss: 0.0471: 100%|██████████| 916/916 [00:18<00:00, 48.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exp 32, Epoch [8/10], Loss: 0.0662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exp 32, Epoch [9/10], Loss: 0.0264: 100%|██████████| 916/916 [00:19<00:00, 46.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exp 32, Epoch [9/10], Loss: 0.0537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exp 32, Epoch [10/10], Loss: 0.0627: 100%|██████████| 916/916 [00:20<00:00, 44.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exp 32, Epoch [10/10], Loss: 0.0448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exp 32, Token Acc: 0.9281, Seq Acc: 0.6701:  20%|██        | 97/480 [02:33<10:04,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9281246482243659\n",
      "0.6701030927835051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# experiments = [0] # [, 1, 2, 4, 8, 16, 32]\n",
    "experiment = '32'\n",
    "\n",
    "exp_losses = []\n",
    "exp_accuracies = []\n",
    "exp_times = []\n",
    "token_acc_results = []\n",
    "seq_scc_results = []\n",
    "num_epochs = 10\n",
    "\n",
    "print(f\"EXPERIMENT {experiment}\")\n",
    "train_data = TasksData(data_dir='./data/Experiment-3/size_variations_v2', file=f'tasks_train_addprim_complex_jump_num{experiment}.txt') \n",
    "test_data = TasksData(data_dir='./data/Experiment-3/size_variations_v2', file=f'tasks_test_addprim_complex_jump_num{experiment}.txt') \n",
    "\n",
    "# creating source and target vocab - and word2idx\n",
    "src_train_data = [src for src, tgt in train_data]\n",
    "vocab_train_src = create_vocab(src_train_data)\n",
    "tgt_train_data = [tgt for src, tgt in train_data]\n",
    "vocab_train_tgt = create_vocab(tgt_train_data)\n",
    "word2idx_src = {w: idx + 1 for (idx, w) in enumerate(vocab_train_src)}\n",
    "word2idx_src['<PAD>'] = 0\n",
    "word2idx_tgt= {w: idx + 1 for (idx, w) in enumerate(vocab_train_tgt)}\n",
    "word2idx_tgt['<PAD>'] = 0\n",
    "\n",
    "# custom collate function\n",
    "def custom_collate_fn(batch):\n",
    "    padded_src = pad_sequence([torch.tensor([word2idx_src[w] for w in src.split()]) for src, tgt in batch], batch_first=True, padding_value=0).to(device)\n",
    "    padded_tgt = pad_sequence([torch.tensor([word2idx_tgt[w] for w in tgt.split()]) for src, tgt in batch], batch_first=True, padding_value=0).to(device)\n",
    "    return padded_src, padded_tgt\n",
    "\n",
    "# create dataloaders\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, collate_fn=custom_collate_fn)\n",
    "test_loader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False, collate_fn=custom_collate_fn)\n",
    "\n",
    "\n",
    "# define the model\n",
    "model = Transformer(\n",
    "    src_vocab_size=len(word2idx_src),\n",
    "    tgt_vocab_size=len(word2idx_tgt),\n",
    "    src_pad_idx=word2idx_src['<PAD>'],\n",
    "    tgt_pad_idx=word2idx_tgt['<PAD>'],\n",
    "    emb_dim=EMB_DIM,\n",
    "    num_layers=N_LAYERS,\n",
    "    num_heads=N_HEADS,\n",
    "    forward_dim=FORWARD_DIM,\n",
    "    dropout=DROPOUT,\n",
    "    max_len=MAX_LEN,\n",
    ").to(device)\n",
    "\n",
    "\n",
    "# define the optimizer and loss function\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=word2idx_tgt['<PAD>'])\n",
    "\n",
    "losses = []\n",
    "accuracies = []\n",
    "\n",
    "# training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for step, (src, tgt) in (pbar := tqdm(enumerate(train_loader), total=len(train_loader))):\n",
    "        src, tgt = src.to(device), tgt.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # inference\n",
    "        output = model(src, tgt[:, :-1])\n",
    "        output_dim = output.shape[-1]\n",
    "\n",
    "        # some sexy reshaping\n",
    "        output = output.contiguous().view(-1, output_dim)\n",
    "        tgt = tgt[:, 1:].contiguous().view(-1)\n",
    "\n",
    "        # loss calculation + backward pass\n",
    "        loss = criterion(output, tgt)\n",
    "        loss.backward()\n",
    "\n",
    "        # Gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), GRAD_CLIP)\n",
    "        pbar.set_description(f'Exp {experiment}, Epoch [{epoch+1}/{num_epochs}], Loss: {loss:.4f}')\n",
    "\n",
    "        # optimizer step and loss accumulation\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    # after one epoch\n",
    "    avg_epoch_loss = epoch_loss / len(train_loader)\n",
    "    losses.append(avg_epoch_loss)\n",
    "    print(f'Exp {experiment}, Epoch [{epoch+1}/{num_epochs}], Loss: {avg_epoch_loss:.4f}')\n",
    "\n",
    "# save the model\n",
    "checkpoint_path = f\"exp3_jump_num{experiment}_epoch{num_epochs}_v2.pth\"\n",
    "torch.save(\n",
    "    {'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'losses': losses\n",
    "}, checkpoint_path)\n",
    "\n",
    "# loss globally\n",
    "exp_losses.append(losses)\n",
    "\n",
    "token_tmp = []\n",
    "seq_tmp = []\n",
    "MAX_STEP = len(test_loader) // 5\n",
    "\n",
    "for step, (src_batch, tgt_batch) in (pbar := tqdm(enumerate(test_loader), total=len(test_loader))):\n",
    "    if step > MAX_STEP:\n",
    "        break\n",
    "    for src, tgt in zip(src_batch, tgt_batch):\n",
    "        src = src.unsqueeze(0).to(device)\n",
    "        true_tgt = tgt.unsqueeze(0).to(device)\n",
    "        tgt = torch.tensor([[word2idx_tgt['<SOS>']]]).to(device)\n",
    "        \n",
    "        iterations = MAX_LEN - 1\n",
    "        pred_sequence = [tgt.item()]\n",
    "\n",
    "        for i in range(iterations):\n",
    "            with torch.no_grad():\n",
    "                output = model.forward(src, tgt)\n",
    "                predictions = nn.functional.softmax(output[:, -1, :], dim=-1)\n",
    "                next_token = predictions.argmax(-1).item()\n",
    "\n",
    "                pred_sequence.append(next_token)\n",
    "                tgt = torch.tensor(pred_sequence).unsqueeze(0).to(device)\n",
    "                \n",
    "                # stop if end of sequence\n",
    "                if next_token == word2idx_tgt['<EOS>']:\n",
    "                    break\n",
    "\n",
    "        token_acc = token_lvl_accuracy(word2idx_tgt, true_tgt, tgt)\n",
    "        seq_acc = sequence_level_accuracy(true_tgt, tgt, word2idx_tgt)\n",
    "        token_tmp.append(token_acc)\n",
    "        seq_tmp.append(seq_acc)\n",
    "        # print(f'ground t: {true_tgt}')\n",
    "        # print(f'predicted: {tgt}')\n",
    "        # print(m)\n",
    "        # print()\n",
    "    # l += 1\n",
    "    \n",
    "    pbar.set_description(f'Exp {experiment}, Token Acc: {sum(token_tmp)/len(token_tmp):.4f}, Seq Acc: {sum(seq_tmp)/len(seq_tmp):.4f}')\n",
    "print(sum(token_tmp)/len(token_tmp))\n",
    "print(sum(seq_tmp)/len(seq_tmp))\n",
    "\n",
    "token_acc_results.append(token_tmp)\n",
    "seq_scc_results.append(seq_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
