{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformer import Transformer\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "# %%\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = torch.device('mps')\n",
    "# EXPERIMENT 1:\n",
    "EMB_DIM = 128\n",
    "N_LAYERS = 1\n",
    "N_HEADS = 8\n",
    "FORWARD_DIM = 512\n",
    "DROPOUT = 0.05\n",
    "LEARNING_RATE = 7e-4\n",
    "BATCH_SIZE = 64\n",
    "GRAD_CLIP = 1\n",
    "MAX_LEN = 128 # ????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On cpu\n"
     ]
    }
   ],
   "source": [
    "print(f\"On {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 0: DataLoader and Preprocessing\n",
    "class TasksData(Dataset):\n",
    "    def __init__(self, data_dir, file, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.file = file\n",
    "        text_file = os.path.join(data_dir, file)\n",
    "\n",
    "        data_dict = {\"src\": [], \"tgt\": []}\n",
    "\n",
    "        with open(text_file, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            for line in lines:\n",
    "                src = line.split('OUT:')[0]\n",
    "                src = src.split('IN:')[1].strip()\n",
    "                tgt = line.split('OUT:')[1].strip()\n",
    "\n",
    "                data_dict['src'].append(src)\n",
    "                data_dict['tgt'].append(tgt)\n",
    "\n",
    "        self.data = pd.DataFrame(data_dict)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        src = self.data['src'].iloc[idx] + ' <EOS>'\n",
    "        tgt = '<SOS> ' + self.data['tgt'].iloc[idx] + ' <EOS>'\n",
    "        return src, tgt\n",
    "\n",
    "def create_vocab(dataset):\n",
    "    vocab = set()\n",
    "\n",
    "    for sample in dataset:\n",
    "        vocab.update(sample.split())\n",
    "    return vocab\n",
    "\n",
    "# %%\n",
    "# creating datasets\n",
    "train_data = TasksData(data_dir='./data', file='tasks_train_simple.txt')\n",
    "test_data = TasksData(data_dir='./data', file='tasks_test_simple.txt')\n",
    "\n",
    "#creating source and target vocab\n",
    "src_train_data = [src for src, tgt in train_data]\n",
    "vocab_train_src = create_vocab(src_train_data)\n",
    "\n",
    "tgt_train_data = [tgt for src, tgt in train_data]\n",
    "vocab_train_tgt = create_vocab(tgt_train_data)\n",
    "\n",
    "# we need to do word2idx to map the words to indexes. Bc the input for nn.Embedding has to be numbers\n",
    "# since nn.Embdding has different weights in input andoutput embedding the same index will not be encoded to the same vector\n",
    "word2idx_src = {w: idx + 1 for (idx, w) in enumerate(vocab_train_src)}\n",
    "word2idx_src['<PAD>'] = 0\n",
    "\n",
    "word2idx_tgt= {w: idx + 1 for (idx, w) in enumerate(vocab_train_tgt)}\n",
    "word2idx_tgt['<PAD>'] = 0\n",
    "\n",
    "# We need Vocabulary size without padding\n",
    "# word2idx\n",
    "# padding\n",
    "#vocabulary and word2idx\n",
    "\n",
    "def custom_collate_fn(batch):\n",
    "    #input: batch of sentences\n",
    "    # tokenize, word2idx, pad\n",
    "    padded_src = pad_sequence([torch.tensor([word2idx_src[w] for w in src.split()]) for src, tgt in batch], batch_first=True, padding_value=0).to(device)\n",
    "    padded_tgt = pad_sequence([torch.tensor([word2idx_tgt[w] for w in tgt.split()]) for src, tgt in batch], batch_first=True, padding_value=0).to(device)\n",
    "\n",
    "    return padded_src, padded_tgt\n",
    "\n",
    "# %%\n",
    "# create dataloaders\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, collate_fn=custom_collate_fn)\n",
    "test_loader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False, collate_fn=custom_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "model = Transformer(\n",
    "    src_vocab_size=len(word2idx_src),\n",
    "    tgt_vocab_size=len(word2idx_tgt),\n",
    "    src_pad_idx=word2idx_src['<PAD>'],\n",
    "    tgt_pad_idx=word2idx_tgt['<PAD>'],\n",
    "    emb_dim=EMB_DIM,\n",
    "    num_layers=N_LAYERS,\n",
    "    num_heads=N_HEADS,\n",
    "    forward_dim=FORWARD_DIM,\n",
    "    dropout=DROPOUT,\n",
    "    max_len=MAX_LEN,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ACCURACY FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_lvl_accuracy(gt, pred):\n",
    "    \"\"\"\n",
    "    gt = ground truth sequence\n",
    "    pred = predicted sequence\n",
    "    \"\"\"\n",
    "    correct = 0\n",
    "    \n",
    "    # get start and end\n",
    "    eos_idx = word2idx_tgt['<EOS>']\n",
    "    sos_idx = word2idx_tgt['<SOS>']\n",
    "    # print(eos_idx)\n",
    "    # print(sos_idx)\n",
    "    pred = pred[-1]\n",
    "\n",
    "\n",
    "    gt = gt[-1]\n",
    "\n",
    "    # index of <SOS> and <EOS> tokens of the predicted sequence\n",
    "    pred_start = 0\n",
    "    pred_end = len(pred) if (eos_idx not in pred) else (pred == eos_idx).nonzero(as_tuple=True)[0].item()\n",
    "\n",
    "    # index of <SOS> and <EOS> tokens of the ground truth sequence\n",
    "    gt_start = (gt == sos_idx).nonzero(as_tuple=True)[0].item()\n",
    "    gt_end = (gt == eos_idx).nonzero(as_tuple=True)[0].item()\n",
    "\n",
    "    # slicing\n",
    "    gt = gt[gt_start+1 : gt_end]\n",
    "    pred = pred[pred_start+1 : pred_end]\n",
    "\n",
    "    longer = gt if len(gt) > len(pred) else pred\n",
    "    shorter = pred if len(gt) > len(pred) else gt\n",
    "\n",
    "    longest_len = len(longer)\n",
    "\n",
    "    shorter = torch.nn.functional.pad(shorter, (0, longest_len - len(shorter)), \"constant\", 0)\n",
    "\n",
    "    correct = sum(longer == shorter)\n",
    "    # print(longer)\n",
    "    # print(shorter)\n",
    "    # print(correct)\n",
    "    return int(correct) / len(shorter) # same length as longer\n",
    "\n",
    "\n",
    "def sequence_level_accuracy(gt, pred):\n",
    "\n",
    "    pred = pred[-1]\n",
    "    gt = gt[-1]\n",
    "\n",
    "    if len(gt) != len(pred):\n",
    "        return 0\n",
    "\n",
    "    if sum(gt == pred) == len(gt):\n",
    "        return 1\n",
    "\n",
    "    return 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/262 [00:00<?, ?it/s]/home/jljubas/projects/ATNLP-project/crispy-fortnight/transformer.py:187: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3683.)\n",
      "  K_transposed = K.T.permute(3, 1, 0, 2)\n",
      "Epoch [1/2], Loss: 0.2558: 100%|██████████| 262/262 [00:58<00:00,  4.52it/s]\n",
      "Epoch [2/2], Loss: 0.0957: 100%|██████████| 262/262 [00:55<00:00,  4.74it/s]\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=word2idx_tgt['<PAD>'])\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 2\n",
    "losses = []\n",
    "accuraacy = []\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for step, (src, tgt) in (pbar := tqdm(enumerate(train_loader), total=len(train_loader))):\n",
    "        src, tgt = src.to(device), tgt.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # output = model(src, tgt)\n",
    "        output = model(src, tgt[:, :-1])\n",
    "        output_dim = output.shape[-1]\n",
    "\n",
    "        output = output.contiguous().view(-1, output_dim)\n",
    "        tgt = tgt[:, 1:].contiguous().view(-1)\n",
    "\n",
    "        loss = criterion(output, tgt)\n",
    "        loss.backward()\n",
    "\n",
    "        # Gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), GRAD_CLIP)\n",
    "\n",
    "        pbar.set_description(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss:.4f}')\n",
    "\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    avg_epoch_loss = epoch_loss / len(train_loader)\n",
    "    losses.append(avg_epoch_loss)\n",
    "checkpoint_path = f\"transformer_exp1_15.pth\"\n",
    "torch.save(\n",
    "    {'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "}, checkpoint_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(losses)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(1)\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reverse the word-to-index mapping\n",
    "idx2word_src = {idx: w for w, idx in word2idx_src.items()}\n",
    "idx2word_tgt = {idx: w for w, idx in word2idx_tgt.items()}\n",
    "\n",
    "def decode_indices(indices, idx2word):\n",
    "    return ' '.join(idx2word[idx] for idx in indices if idx in idx2word and idx != word2idx_src['<PAD>'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1193004/4206279624.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckp = torch.load(checkpoint_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])\n",
      "tensor([[ 6, 12,  8, 14,  5,  6, 12,  4, 13,  0]])\n",
      "ground t: tensor([[5, 3, 3, 3, 3, 3, 3, 4, 4, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "predicted: tensor([[5, 3, 3, 3, 3, 3, 3, 4, 4, 8]])\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = f\"transformer_exp1_2-epochs.pth\"\n",
    "ckp = torch.load(checkpoint_path)\n",
    "model.load_state_dict(ckp['model_state_dict'])\n",
    "total_tokens = 0\n",
    "correct_tokens = 0\n",
    "\n",
    "def inference(input_seq: str):\n",
    "    model.eval()\n",
    "    pass\n",
    "\n",
    "model.eval()\n",
    "\n",
    "src, true_tgt = next(iter(test_loader))\n",
    "print(src.shape)\n",
    "src = src[0].unsqueeze(0).to(device)\n",
    "true_tgt = true_tgt[0].unsqueeze(0).to(device)\n",
    "# src, true_tgt = next(iter(test_loader))[0][0].unsqueeze(0).to(device)\n",
    "\n",
    "print(src)\n",
    "tgt = torch.tensor([[word2idx_tgt['<SOS>']]]).to(device)\n",
    "# tgt = torch.tensor([[word2idx_tgt['<SOS>']]]).to(device)\n",
    "\n",
    "# print(f'tgt {tgt.shape}')\n",
    "# print(f'src {src.shape}')\n",
    "iterations = 20\n",
    "pred_sequence = [tgt.item()]\n",
    "# print(pred_sequence)\n",
    "\n",
    "for i in range(iterations):\n",
    "    with torch.no_grad():\n",
    "        # print(tgt)\n",
    "        output = model.forward(src, tgt)\n",
    "        predictions = nn.functional.softmax(output[:, -1, :], dim=-1)\n",
    "        # print(\"argmax:\", predictions.argmax(-1).shape)\n",
    "        next_token = predictions.argmax(-1).item()\n",
    "\n",
    "\n",
    "        # next_token_tensor = torch.tensor([[next_token]]).to(device)\n",
    "        # tgt = torch.cat([tgt, next_token_tensor], dim=1)\n",
    "        \n",
    "        pred_sequence.append(next_token)\n",
    "        tgt = torch.tensor(pred_sequence).unsqueeze(0).to(device)\n",
    "\n",
    "        if next_token == word2idx_tgt['<EOS>']:\n",
    "            break\n",
    "        \n",
    "        # print(tgt.shape)\n",
    "        # print(\"tgt\", tgt)\n",
    "\n",
    "print(f'ground t: {true_tgt}')\n",
    "print(f'predicted: {tgt}')\n",
    "print(token_lvl_accuracy(true_tgt, tgt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "print(word2idx_tgt['<SOS>'])\n",
    "print(word2idx_tgt['<EOS>'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BATCH INFERENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1194929/3454905486.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckp = torch.load(checkpoint_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01954220103740925\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = \"transformer_exp1_2-epochs.pth\"\n",
    "ckp = torch.load(checkpoint_path)\n",
    "model.load_state_dict(ckp['model_state_dict'])\n",
    "total_tokens = 0\n",
    "correct_tokens = 0\n",
    "\n",
    "src, tgt = next(iter(test_loader))\n",
    "# print(src.shape, tgt.shape)\n",
    "avg_token = []\n",
    "avg_seq = []\n",
    "\n",
    "# l = 0\n",
    "# for src_batch, tgt_batch in test_loader[:10]:\n",
    "#     # if l > 5:\n",
    "#     #     break\n",
    "\n",
    "src_batch, tgt_batch = next(iter(test_loader))\n",
    "\n",
    "for src, tgt in zip(src_batch, tgt_batch):\n",
    "    # \n",
    "    src = src.unsqueeze(0).to(device)\n",
    "    true_tgt = tgt.unsqueeze(0).to(device)\n",
    "    tgt = torch.tensor([[word2idx_tgt['<SOS>']]]).to(device)\n",
    "    \n",
    "    iterations = MAX_LEN - 1\n",
    "    pred_sequence = [tgt.item()]\n",
    "    # print(tgt.shape)\n",
    "    # print(src.shape, true_tgt.shape)\n",
    "\n",
    "    for i in range(iterations):\n",
    "        with torch.no_grad():\n",
    "            output = model.forward(src, tgt)\n",
    "            predictions = nn.functional.softmax(output[:, -1, :], dim=-1)\n",
    "            next_token = predictions.argmax(-1).item()\n",
    "\n",
    "            pred_sequence.append(next_token)\n",
    "            tgt = torch.tensor(pred_sequence).unsqueeze(0).to(device)\n",
    "            \n",
    "            # Stop if end of sequence\n",
    "            if next_token == word2idx_tgt['<EOS>']:\n",
    "                break                \n",
    "\n",
    "    m = token_lvl_accuracy(true_tgt, tgt)\n",
    "    avg_token.append(m)\n",
    "\n",
    "    seq_acc = sequence_level_accuracy(true_tgt, tgt)\n",
    "    avg_seq.append(seq_acc)\n",
    "    \n",
    "print(sum(avg_token)/len(avg_token))\n",
    "\n",
    "print(sum(avg_seq)/len(avg_seq))\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
