{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformer import Transformer\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "# %%\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = torch.device('mps')\n",
    "# EXPERIMENT 1:\n",
    "EMB_DIM = 128\n",
    "N_LAYERS = 1\n",
    "N_HEADS = 8\n",
    "FORWARD_DIM = 512\n",
    "DROPOUT = 0.05\n",
    "LEARNING_RATE = 7e-4\n",
    "BATCH_SIZE = 64\n",
    "GRAD_CLIP = 1\n",
    "MAX_LEN = 128 # ????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On cuda\n"
     ]
    }
   ],
   "source": [
    "print(f\"On {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 0: DataLoader and Preprocessing\n",
    "class TasksData(Dataset):\n",
    "    def __init__(self, data_dir, file, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.file = file\n",
    "        text_file = os.path.join(data_dir, file)\n",
    "\n",
    "        data_dict = {\"src\": [], \"tgt\": []}\n",
    "\n",
    "        with open(text_file, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            for line in lines:\n",
    "                src = line.split('OUT:')[0]\n",
    "                src = src.split('IN:')[1].strip()\n",
    "                tgt = line.split('OUT:')[1].strip()\n",
    "\n",
    "                data_dict['src'].append(src)\n",
    "                data_dict['tgt'].append(tgt)\n",
    "\n",
    "        self.data = pd.DataFrame(data_dict)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        src = self.data['src'].iloc[idx] + ' <EOS>'\n",
    "        tgt = '<SOS> ' + self.data['tgt'].iloc[idx] + ' <EOS>'\n",
    "        return src, tgt\n",
    "\n",
    "def create_vocab(dataset):\n",
    "    vocab = set()\n",
    "\n",
    "    for sample in dataset:\n",
    "        vocab.update(sample.split())\n",
    "    return vocab\n",
    "\n",
    "# %%\n",
    "# creating datasets\n",
    "train_data = TasksData(data_dir='./data', file='tasks_train_simple.txt')\n",
    "test_data = TasksData(data_dir='./data', file='tasks_test_simple.txt')\n",
    "\n",
    "#creating source and target vocab\n",
    "src_train_data = [src for src, tgt in train_data]\n",
    "vocab_train_src = create_vocab(src_train_data)\n",
    "\n",
    "tgt_train_data = [tgt for src, tgt in train_data]\n",
    "vocab_train_tgt = create_vocab(tgt_train_data)\n",
    "\n",
    "# we need to do word2idx to map the words to indexes. Bc the input for nn.Embedding has to be numbers\n",
    "# since nn.Embdding has different weights in input andoutput embedding the same index will not be encoded to the same vector\n",
    "word2idx_src = {w: idx + 1 for (idx, w) in enumerate(vocab_train_src)}\n",
    "word2idx_src['<PAD>'] = 0\n",
    "\n",
    "word2idx_tgt= {w: idx + 1 for (idx, w) in enumerate(vocab_train_tgt)}\n",
    "word2idx_tgt['<PAD>'] = 0\n",
    "\n",
    "# We need Vocabulary size without padding\n",
    "# word2idx\n",
    "# padding\n",
    "#vocabulary and word2idx\n",
    "\n",
    "def custom_collate_fn(batch):\n",
    "    #input: batch of sentences\n",
    "    # tokenize, word2idx, pad\n",
    "    padded_src = pad_sequence([torch.tensor([word2idx_src[w] for w in src.split()]) for src, tgt in batch], batch_first=True, padding_value=0).to(device)\n",
    "    padded_tgt = pad_sequence([torch.tensor([word2idx_tgt[w] for w in tgt.split()]) for src, tgt in batch], batch_first=True, padding_value=0).to(device)\n",
    "\n",
    "    return padded_src, padded_tgt\n",
    "\n",
    "# %%\n",
    "# create dataloaders\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, collate_fn=custom_collate_fn)\n",
    "test_loader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False, collate_fn=custom_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "model = Transformer(\n",
    "    src_vocab_size=len(word2idx_src),\n",
    "    tgt_vocab_size=len(word2idx_tgt),\n",
    "    src_pad_idx=word2idx_src['<PAD>'],\n",
    "    tgt_pad_idx=word2idx_tgt['<PAD>'],\n",
    "    emb_dim=EMB_DIM,\n",
    "    num_layers=N_LAYERS,\n",
    "    num_heads=N_HEADS,\n",
    "    forward_dim=FORWARD_DIM,\n",
    "    dropout=DROPOUT,\n",
    "    max_len=MAX_LEN,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Token Level Acc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_lvl_accuracy(gt, pred):\n",
    "    correct = 0\n",
    "    i = 0\n",
    "\n",
    "    # get start and end\n",
    "    eos_idx = word2idx_tgt['<EOS>']\n",
    "    sos_idx = word2idx_tgt['<SOS>']\n",
    "    # print(eos_idx)\n",
    "    # print(sos_idx)\n",
    "    pred = pred[-1]\n",
    "    gt = gt[-1]\n",
    "\n",
    "    pred_start = (pred == sos_idx).nonzero(as_tuple=True)[0].item()\n",
    "    pred_end = (pred == eos_idx).nonzero(as_tuple=True)[0].item()\n",
    "\n",
    "    gt_start = (gt == sos_idx).nonzero(as_tuple=True)[0].item()\n",
    "    gt_end = (gt == eos_idx).nonzero(as_tuple=True)[0].item()\n",
    "\n",
    "    # slicing\n",
    "    gt = gt[gt_start+1 : gt_end]\n",
    "    pred = pred[pred_start+1 : pred_end]\n",
    "\n",
    "    longer = gt if len(gt) > len(pred) else pred\n",
    "    shorter = pred if len(gt) > len(pred) else gt\n",
    "\n",
    "    longest_len = len(longer)\n",
    "\n",
    "    shorter = torch.nn.functional.pad(shorter, (0, longest_len - len(shorter)), \"constant\", 0)\n",
    "\n",
    "    correct = sum(longer == shorter)\n",
    "    # print(longer)\n",
    "    # print(shorter)\n",
    "    # print(correct)\n",
    "    return int(correct) / len(shorter) # same length as longer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/262 [00:00<?, ?it/s]c:\\Users\\magnu\\UCPH\\9-Semester\\Advanced-Topics-in-Natural-Language-Processing\\crispy-fortnight\\transformer.py:187: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\TensorShape.cpp:3701.)\n",
      "  K_transposed = K.T.permute(3, 1, 0, 2)\n",
      "Epoch [1/15], Loss: 0.2396: 100%|██████████| 262/262 [00:05<00:00, 43.80it/s]\n",
      "Epoch [2/15], Loss: 0.0822: 100%|██████████| 262/262 [00:03<00:00, 65.79it/s]\n",
      "Epoch [3/15], Loss: 0.0755: 100%|██████████| 262/262 [00:06<00:00, 41.07it/s]\n",
      "Epoch [4/15], Loss: 0.0385: 100%|██████████| 262/262 [00:04<00:00, 54.91it/s]\n",
      "Epoch [5/15], Loss: 0.0411: 100%|██████████| 262/262 [00:04<00:00, 61.74it/s]\n",
      "Epoch [6/15], Loss: 0.0197: 100%|██████████| 262/262 [00:04<00:00, 64.62it/s]\n",
      "Epoch [7/15], Loss: 0.0160: 100%|██████████| 262/262 [00:04<00:00, 64.05it/s]\n",
      "Epoch [8/15], Loss: 0.0189: 100%|██████████| 262/262 [00:05<00:00, 47.66it/s]\n",
      "Epoch [9/15], Loss: 0.0257: 100%|██████████| 262/262 [00:04<00:00, 60.59it/s]\n",
      "Epoch [10/15], Loss: 0.0050: 100%|██████████| 262/262 [00:06<00:00, 40.45it/s]\n",
      "Epoch [11/15], Loss: 0.0056: 100%|██████████| 262/262 [00:07<00:00, 35.87it/s]\n",
      "Epoch [12/15], Loss: 0.0058: 100%|██████████| 262/262 [00:05<00:00, 49.08it/s]\n",
      "Epoch [13/15], Loss: 0.0101: 100%|██████████| 262/262 [00:05<00:00, 44.39it/s]\n",
      "Epoch [14/15], Loss: 0.0029: 100%|██████████| 262/262 [00:04<00:00, 59.39it/s]\n",
      "Epoch [15/15], Loss: 0.0070: 100%|██████████| 262/262 [00:06<00:00, 41.48it/s]\n"
     ]
    }
   ],
   "source": [
    "# model = Transformer(\n",
    "#     src_vocab_size=len(word2idx_src),\n",
    "#     tgt_vocab_size=len(word2idx_tgt),\n",
    "#     src_pad_idx=word2idx_src['<PAD>'],\n",
    "#     tgt_pad_idx=word2idx_tgt['<PAD>'],\n",
    "#     emb_dim=EMB_DIM,\n",
    "#     num_layers=N_LAYERS,\n",
    "#     num_heads=N_HEADS,\n",
    "#     forward_dim=FORWARD_DIM,\n",
    "#     dropout=DROPOUT,\n",
    "#     max_len=MAX_LEN,\n",
    "# ).to(device)\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=word2idx_tgt['<PAD>'])\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 15\n",
    "losses = []\n",
    "accuraacy = []\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for step, (src, tgt) in (pbar := tqdm(enumerate(train_loader), total=len(train_loader))):\n",
    "        src, tgt = src.to(device), tgt.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # output = model(src, tgt)\n",
    "        output = model(src, tgt[:, :-1])\n",
    "        output_dim = output.shape[-1]\n",
    "\n",
    "        output = output.contiguous().view(-1, output_dim)\n",
    "        tgt = tgt[:, 1:].contiguous().view(-1)\n",
    "\n",
    "        loss = criterion(output, tgt)\n",
    "        loss.backward()\n",
    "\n",
    "        # Gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), GRAD_CLIP)\n",
    "\n",
    "        pbar.set_description(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss:.4f}')\n",
    "\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    avg_epoch_loss = epoch_loss / len(train_loader)\n",
    "    losses.append(avg_epoch_loss)\n",
    "checkpoint_path = f\"transformer_exp1_15.pth\"\n",
    "torch.save(\n",
    "    {'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "}, checkpoint_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1f351fabd70>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(1)\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reverse the word-to-index mapping\n",
    "idx2word_src = {idx: w for w, idx in word2idx_src.items()}\n",
    "idx2word_tgt = {idx: w for w, idx in word2idx_tgt.items()}\n",
    "\n",
    "def decode_indices(indices, idx2word):\n",
    "    return ' '.join(idx2word[idx] for idx in indices if idx in idx2word and idx != word2idx_src['<PAD>'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TOKEN LEVEL ACC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = f\"transformer_exp1_100.pth\"\n",
    "ckp = torch.load(checkpoint_path)\n",
    "model.load_state_dict(ckp['model_state_dict'])\n",
    "total_tokens = 0\n",
    "correct_tokens = 0\n",
    "\n",
    "def inference(input_seq: str):\n",
    "    model.eval()\n",
    "    pass\n",
    "\n",
    "model.eval()\n",
    "\n",
    "src, true_tgt = next(iter(test_loader))\n",
    "print(src.shape)\n",
    "src = src[0].unsqueeze(0).to(device)\n",
    "true_tgt = true_tgt[0].unsqueeze(0).to(device)\n",
    "# src, true_tgt = next(iter(test_loader))[0][0].unsqueeze(0).to(device)\n",
    "\n",
    "print(src)\n",
    "tgt = torch.tensor([[word2idx_tgt['<SOS>']]]).to(device)\n",
    "# tgt = torch.tensor([[word2idx_tgt['<SOS>']]]).to(device)\n",
    "\n",
    "# print(f'tgt {tgt.shape}')\n",
    "# print(f'src {src.shape}')\n",
    "iterations = 20\n",
    "pred_sequence = [tgt.item()]\n",
    "# print(pred_sequence)\n",
    "\n",
    "for i in range(iterations):\n",
    "    with torch.no_grad():\n",
    "        # print(tgt)\n",
    "        output = model.forward(src, tgt)\n",
    "        predictions = nn.functional.softmax(output[:, -1, :], dim=-1)\n",
    "        # print(\"argmax:\", predictions.argmax(-1).shape)\n",
    "        next_token = predictions.argmax(-1).item()\n",
    "\n",
    "\n",
    "        # next_token_tensor = torch.tensor([[next_token]]).to(device)\n",
    "        # tgt = torch.cat([tgt, next_token_tensor], dim=1)\n",
    "        \n",
    "        pred_sequence.append(next_token)\n",
    "        tgt = torch.tensor(pred_sequence).unsqueeze(0).to(device)\n",
    "\n",
    "        if next_token == word2idx_tgt['<EOS>']:\n",
    "            break\n",
    "        \n",
    "        # print(tgt.shape)\n",
    "        # print(\"tgt\", tgt)\n",
    "\n",
    "print(f'ground t: {true_tgt}')\n",
    "print(f'predicted: {tgt}')\n",
    "print(token_lvl_accuracy(true_tgt, tgt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "print(word2idx_tgt['<SOS>'])\n",
    "print(word2idx_tgt['<EOS>'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BATCH INFERENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\magnu\\AppData\\Local\\Temp\\ipykernel_11892\\3057734478.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckp = torch.load(checkpoint_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9911292819381053\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = f\"transformer_exp1_15.pth\"\n",
    "ckp = torch.load(checkpoint_path)\n",
    "model.load_state_dict(ckp['model_state_dict'])\n",
    "total_tokens = 0\n",
    "correct_tokens = 0\n",
    "\n",
    "src, tgt = next(iter(test_loader))\n",
    "# print(src.shape, tgt.shape)\n",
    "avg = []\n",
    "\n",
    "# l = 0\n",
    "\n",
    "for src_batch, tgt_batch in test_loader:\n",
    "    # if l > 5:\n",
    "    #     break\n",
    "    for src, tgt in zip(src_batch, tgt_batch):\n",
    "        # print(src)\n",
    "        # \n",
    "        src = src.unsqueeze(0).to(device)\n",
    "        true_tgt = tgt.unsqueeze(0).to(device)\n",
    "        tgt = torch.tensor([[word2idx_tgt['<SOS>']]]).to(device)\n",
    "        \n",
    "        iterations = MAX_LEN\n",
    "        pred_sequence = [tgt.item()]\n",
    "        # print(tgt.shape)\n",
    "        # print(src.shape, true_tgt.shape)\n",
    "\n",
    "        for i in range(iterations):\n",
    "            with torch.no_grad():\n",
    "                output = model.forward(src, tgt)\n",
    "                predictions = nn.functional.softmax(output[:, -1, :], dim=-1)\n",
    "                next_token = predictions.argmax(-1).item()\n",
    "\n",
    "                pred_sequence.append(next_token)\n",
    "                tgt = torch.tensor(pred_sequence).unsqueeze(0).to(device)\n",
    "                \n",
    "                # Stop if end of sequence\n",
    "                if next_token == word2idx_tgt['<EOS>']:\n",
    "                    break\n",
    "\n",
    "        m = token_lvl_accuracy(true_tgt, tgt)\n",
    "        avg.append(m)\n",
    "        # print(f'ground t: {true_tgt}')\n",
    "        # print(f'predicted: {tgt}')\n",
    "        # print(m)\n",
    "        # print()\n",
    "    # l += 1\n",
    "    \n",
    "print(sum(avg)/len(avg))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
