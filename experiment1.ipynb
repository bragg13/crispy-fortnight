{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformer import Transformer\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "# %%\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = torch.device('mps')\n",
    "# EXPERIMENT 1:\n",
    "EMB_DIM = 128\n",
    "N_LAYERS = 1\n",
    "N_HEADS = 8\n",
    "FORWARD_DIM = 512\n",
    "DROPOUT = 0.05\n",
    "LEARNING_RATE = 7e-4\n",
    "BATCH_SIZE = 64\n",
    "GRAD_CLIP = 1\n",
    "MAX_LEN = 128 # ????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On cuda\n"
     ]
    }
   ],
   "source": [
    "print(f\"On {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 0: DataLoader and Preprocessing\n",
    "class TasksData(Dataset):\n",
    "    def __init__(self, data_dir, file, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.file = file\n",
    "        text_file = os.path.join(data_dir, file)\n",
    "\n",
    "        data_dict = {\"src\": [], \"tgt\": []}\n",
    "\n",
    "        with open(text_file, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            for line in lines:\n",
    "                src = line.split('OUT:')[0]\n",
    "                src = src.split('IN:')[1].strip()\n",
    "                tgt = line.split('OUT:')[1].strip()\n",
    "\n",
    "                data_dict['src'].append(src)\n",
    "                data_dict['tgt'].append(tgt)\n",
    "\n",
    "        self.data = pd.DataFrame(data_dict)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        src = self.data['src'].iloc[idx] + ' <EOS>'\n",
    "        tgt = '<SOS> ' + self.data['tgt'].iloc[idx] + ' <EOS>'\n",
    "        return src, tgt\n",
    "\n",
    "def create_vocab(dataset):\n",
    "    vocab = set()\n",
    "\n",
    "    for sample in dataset:\n",
    "        vocab.update(sample.split())\n",
    "    return vocab\n",
    "\n",
    "# %%\n",
    "# creating datasets\n",
    "train_data = TasksData(data_dir='./data', file='tasks_train_simple.txt')\n",
    "test_data = TasksData(data_dir='./data', file='tasks_test_simple.txt')\n",
    "\n",
    "#creating source and target vocab\n",
    "src_train_data = [src for src, tgt in train_data]\n",
    "vocab_train_src = create_vocab(src_train_data)\n",
    "\n",
    "tgt_train_data = [tgt for src, tgt in train_data]\n",
    "vocab_train_tgt = create_vocab(tgt_train_data)\n",
    "\n",
    "# we need to do word2idx to map the words to indexes. Bc the input for nn.Embedding has to be numbers\n",
    "# since nn.Embdding has different weights in input andoutput embedding the same index will not be encoded to the same vector\n",
    "word2idx_src = {w: idx + 1 for (idx, w) in enumerate(vocab_train_src)}\n",
    "word2idx_src['<PAD>'] = 0\n",
    "\n",
    "word2idx_tgt= {w: idx + 1 for (idx, w) in enumerate(vocab_train_tgt)}\n",
    "word2idx_tgt['<PAD>'] = 0\n",
    "\n",
    "# We need Vocabulary size without padding\n",
    "# word2idx\n",
    "# padding\n",
    "#vocabulary and word2idx\n",
    "\n",
    "def custom_collate_fn(batch):\n",
    "    #input: batch of sentences\n",
    "    # tokenize, word2idx, pad\n",
    "    padded_src = pad_sequence([torch.tensor([word2idx_src[w] for w in src.split()]) for src, tgt in batch], batch_first=True, padding_value=0).to(device)\n",
    "    padded_tgt = pad_sequence([torch.tensor([word2idx_tgt[w] for w in tgt.split()]) for src, tgt in batch], batch_first=True, padding_value=0).to(device)\n",
    "\n",
    "    return padded_src, padded_tgt\n",
    "\n",
    "# %%\n",
    "# create dataloaders\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, collate_fn=custom_collate_fn)\n",
    "test_loader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False, collate_fn=custom_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "model = Transformer(\n",
    "    src_vocab_size=len(word2idx_src),\n",
    "    tgt_vocab_size=len(word2idx_tgt),\n",
    "    src_pad_idx=word2idx_src['<PAD>'],\n",
    "    tgt_pad_idx=word2idx_tgt['<PAD>'],\n",
    "    emb_dim=EMB_DIM,\n",
    "    num_layers=N_LAYERS,\n",
    "    num_heads=N_HEADS,\n",
    "    forward_dim=FORWARD_DIM,\n",
    "    dropout=DROPOUT,\n",
    "    max_len=MAX_LEN,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/200], Loss: 0.6641: 100%|██████████| 262/262 [00:03<00:00, 74.88it/s]\n",
      "Epoch [2/200], Loss: 0.6027: 100%|██████████| 262/262 [00:03<00:00, 85.85it/s]\n",
      "Epoch [3/200], Loss: 0.5587: 100%|██████████| 262/262 [00:03<00:00, 87.06it/s]\n",
      "Epoch [4/200], Loss: 0.4091: 100%|██████████| 262/262 [00:03<00:00, 86.84it/s]\n",
      "Epoch [5/200], Loss: 0.3234: 100%|██████████| 262/262 [00:02<00:00, 87.83it/s]\n",
      "Epoch [6/200], Loss: 0.2798: 100%|██████████| 262/262 [00:03<00:00, 86.95it/s]\n",
      "Epoch [7/200], Loss: 0.3201: 100%|██████████| 262/262 [00:03<00:00, 87.10it/s]\n",
      "Epoch [8/200], Loss: 0.2665: 100%|██████████| 262/262 [00:02<00:00, 87.56it/s]\n",
      "Epoch [9/200], Loss: 0.2488: 100%|██████████| 262/262 [00:03<00:00, 86.46it/s]\n",
      "Epoch [10/200], Loss: 0.2503: 100%|██████████| 262/262 [00:03<00:00, 86.81it/s]\n",
      "Epoch [11/200], Loss: 0.3211: 100%|██████████| 262/262 [00:03<00:00, 84.17it/s]\n",
      "Epoch [12/200], Loss: 0.2244: 100%|██████████| 262/262 [00:03<00:00, 83.84it/s]\n",
      "Epoch [13/200], Loss: 0.2623: 100%|██████████| 262/262 [00:03<00:00, 85.98it/s]\n",
      "Epoch [14/200], Loss: 0.2966: 100%|██████████| 262/262 [00:03<00:00, 85.18it/s]\n",
      "Epoch [15/200], Loss: 0.2355: 100%|██████████| 262/262 [00:03<00:00, 83.71it/s]\n",
      "Epoch [16/200], Loss: 0.2328: 100%|██████████| 262/262 [00:03<00:00, 82.10it/s]\n",
      "Epoch [17/200], Loss: 0.2629: 100%|██████████| 262/262 [00:03<00:00, 81.61it/s]\n",
      "Epoch [18/200], Loss: 0.2092: 100%|██████████| 262/262 [00:03<00:00, 81.54it/s]\n",
      "Epoch [19/200], Loss: 0.2743: 100%|██████████| 262/262 [00:03<00:00, 80.47it/s]\n",
      "Epoch [20/200], Loss: 0.1766: 100%|██████████| 262/262 [00:03<00:00, 80.90it/s]\n",
      "Epoch [21/200], Loss: 0.2260: 100%|██████████| 262/262 [00:03<00:00, 75.29it/s]\n",
      "Epoch [22/200], Loss: 0.1553: 100%|██████████| 262/262 [00:03<00:00, 72.84it/s]\n",
      "Epoch [23/200], Loss: 0.1961: 100%|██████████| 262/262 [00:03<00:00, 71.58it/s]\n",
      "Epoch [24/200], Loss: 0.1682: 100%|██████████| 262/262 [00:03<00:00, 71.54it/s]\n",
      "Epoch [25/200], Loss: 0.1776: 100%|██████████| 262/262 [00:03<00:00, 71.20it/s]\n",
      "Epoch [26/200], Loss: 0.2222: 100%|██████████| 262/262 [00:03<00:00, 72.89it/s]\n",
      "Epoch [27/200], Loss: 0.2111: 100%|██████████| 262/262 [00:03<00:00, 73.20it/s]\n",
      "Epoch [28/200], Loss: 0.1674: 100%|██████████| 262/262 [00:03<00:00, 71.68it/s]\n",
      "Epoch [29/200], Loss: 0.1825: 100%|██████████| 262/262 [00:03<00:00, 75.15it/s]\n",
      "Epoch [30/200], Loss: 0.1719: 100%|██████████| 262/262 [00:03<00:00, 79.73it/s]\n",
      "Epoch [31/200], Loss: 0.1591: 100%|██████████| 262/262 [00:03<00:00, 79.92it/s]\n",
      "Epoch [32/200], Loss: 0.2604: 100%|██████████| 262/262 [00:03<00:00, 79.18it/s]\n",
      "Epoch [33/200], Loss: 0.1990: 100%|██████████| 262/262 [00:03<00:00, 80.81it/s]\n",
      "Epoch [34/200], Loss: 0.1457: 100%|██████████| 262/262 [00:03<00:00, 80.55it/s]\n",
      "Epoch [35/200], Loss: 0.2299: 100%|██████████| 262/262 [00:03<00:00, 79.55it/s]\n",
      "Epoch [36/200], Loss: 0.1965: 100%|██████████| 262/262 [00:03<00:00, 76.21it/s]\n",
      "Epoch [37/200], Loss: 0.1665: 100%|██████████| 262/262 [00:03<00:00, 72.85it/s]\n",
      "Epoch [38/200], Loss: 0.1828: 100%|██████████| 262/262 [00:03<00:00, 72.16it/s]\n",
      "Epoch [39/200], Loss: 0.1546: 100%|██████████| 262/262 [00:03<00:00, 67.19it/s]\n",
      "Epoch [40/200], Loss: 0.2133: 100%|██████████| 262/262 [00:03<00:00, 67.02it/s]\n",
      "Epoch [41/200], Loss: 0.1901: 100%|██████████| 262/262 [00:03<00:00, 71.00it/s]\n",
      "Epoch [42/200], Loss: 0.1625: 100%|██████████| 262/262 [00:03<00:00, 75.85it/s]\n",
      "Epoch [43/200], Loss: 0.1954: 100%|██████████| 262/262 [00:03<00:00, 76.14it/s]\n",
      "Epoch [44/200], Loss: 0.1653: 100%|██████████| 262/262 [00:03<00:00, 75.47it/s]\n",
      "Epoch [45/200], Loss: 0.1921: 100%|██████████| 262/262 [00:03<00:00, 70.63it/s]\n",
      "Epoch [46/200], Loss: 0.1875: 100%|██████████| 262/262 [00:03<00:00, 74.11it/s]\n",
      "Epoch [47/200], Loss: 0.1448: 100%|██████████| 262/262 [00:03<00:00, 70.97it/s]\n",
      "Epoch [48/200], Loss: 0.1519: 100%|██████████| 262/262 [00:03<00:00, 75.54it/s]\n",
      "Epoch [49/200], Loss: 0.1411: 100%|██████████| 262/262 [00:03<00:00, 74.20it/s]\n",
      "Epoch [50/200], Loss: 0.1429: 100%|██████████| 262/262 [00:03<00:00, 71.90it/s]\n",
      "Epoch [51/200], Loss: 0.1556: 100%|██████████| 262/262 [00:03<00:00, 72.14it/s]\n",
      "Epoch [52/200], Loss: 0.1650: 100%|██████████| 262/262 [00:03<00:00, 76.21it/s]\n",
      "Epoch [53/200], Loss: 0.1970: 100%|██████████| 262/262 [00:03<00:00, 76.06it/s]\n",
      "Epoch [54/200], Loss: 0.1580: 100%|██████████| 262/262 [00:03<00:00, 74.06it/s]\n",
      "Epoch [55/200], Loss: 0.1480: 100%|██████████| 262/262 [00:03<00:00, 71.89it/s]\n",
      "Epoch [56/200], Loss: 0.1831: 100%|██████████| 262/262 [00:03<00:00, 69.73it/s]\n",
      "Epoch [57/200], Loss: 0.1515: 100%|██████████| 262/262 [00:03<00:00, 73.52it/s]\n",
      "Epoch [58/200], Loss: 0.1670: 100%|██████████| 262/262 [00:03<00:00, 73.84it/s]\n",
      "Epoch [59/200], Loss: 0.1666: 100%|██████████| 262/262 [00:03<00:00, 70.00it/s]\n",
      "Epoch [60/200], Loss: 0.1897: 100%|██████████| 262/262 [00:03<00:00, 71.35it/s]\n",
      "Epoch [61/200], Loss: 0.1842: 100%|██████████| 262/262 [00:03<00:00, 71.65it/s]\n",
      "Epoch [62/200], Loss: 0.1634: 100%|██████████| 262/262 [00:03<00:00, 72.51it/s]\n",
      "Epoch [63/200], Loss: 0.1826: 100%|██████████| 262/262 [00:03<00:00, 73.75it/s]\n",
      "Epoch [64/200], Loss: 0.1461: 100%|██████████| 262/262 [00:03<00:00, 70.11it/s]\n",
      "Epoch [65/200], Loss: 0.2009: 100%|██████████| 262/262 [00:03<00:00, 72.21it/s]\n",
      "Epoch [66/200], Loss: 0.1255: 100%|██████████| 262/262 [00:03<00:00, 73.13it/s]\n",
      "Epoch [67/200], Loss: 0.1533: 100%|██████████| 262/262 [00:03<00:00, 75.97it/s]\n",
      "Epoch [68/200], Loss: 0.1603: 100%|██████████| 262/262 [00:03<00:00, 79.05it/s]\n",
      "Epoch [69/200], Loss: 0.1599: 100%|██████████| 262/262 [00:03<00:00, 80.74it/s]\n",
      "Epoch [70/200], Loss: 0.1631: 100%|██████████| 262/262 [00:03<00:00, 65.93it/s]\n",
      "Epoch [71/200], Loss: 0.1504: 100%|██████████| 262/262 [00:04<00:00, 65.17it/s]\n",
      "Epoch [72/200], Loss: 0.1880: 100%|██████████| 262/262 [00:04<00:00, 64.19it/s]\n",
      "Epoch [73/200], Loss: 0.1226: 100%|██████████| 262/262 [00:03<00:00, 73.42it/s]\n",
      "Epoch [74/200], Loss: 0.1367: 100%|██████████| 262/262 [00:03<00:00, 80.52it/s]\n",
      "Epoch [75/200], Loss: 0.1364: 100%|██████████| 262/262 [00:03<00:00, 80.10it/s]\n",
      "Epoch [76/200], Loss: 0.1393: 100%|██████████| 262/262 [00:03<00:00, 84.47it/s]\n",
      "Epoch [77/200], Loss: 0.1521: 100%|██████████| 262/262 [00:03<00:00, 83.09it/s]\n",
      "Epoch [78/200], Loss: 0.1569: 100%|██████████| 262/262 [00:03<00:00, 81.87it/s]\n",
      "Epoch [79/200], Loss: 0.1123: 100%|██████████| 262/262 [00:03<00:00, 76.18it/s]\n",
      "Epoch [80/200], Loss: 0.1525: 100%|██████████| 262/262 [00:03<00:00, 68.08it/s]\n",
      "Epoch [81/200], Loss: 0.1763: 100%|██████████| 262/262 [00:03<00:00, 70.69it/s]\n",
      "Epoch [82/200], Loss: 0.1565: 100%|██████████| 262/262 [00:03<00:00, 75.40it/s]\n",
      "Epoch [83/200], Loss: 0.1446: 100%|██████████| 262/262 [00:03<00:00, 74.00it/s]\n",
      "Epoch [84/200], Loss: 0.1471: 100%|██████████| 262/262 [00:03<00:00, 72.72it/s]\n",
      "Epoch [85/200], Loss: 0.1661: 100%|██████████| 262/262 [00:03<00:00, 74.51it/s]\n",
      "Epoch [86/200], Loss: 0.1622: 100%|██████████| 262/262 [00:03<00:00, 74.48it/s]\n",
      "Epoch [87/200], Loss: 0.1699: 100%|██████████| 262/262 [00:03<00:00, 72.97it/s]\n",
      "Epoch [88/200], Loss: 0.1287: 100%|██████████| 262/262 [00:03<00:00, 71.08it/s]\n",
      "Epoch [89/200], Loss: 0.1590: 100%|██████████| 262/262 [00:03<00:00, 72.22it/s]\n",
      "Epoch [90/200], Loss: 0.1517: 100%|██████████| 262/262 [00:03<00:00, 76.39it/s]\n",
      "Epoch [91/200], Loss: 0.1690: 100%|██████████| 262/262 [00:03<00:00, 75.60it/s]\n",
      "Epoch [92/200], Loss: 0.1991: 100%|██████████| 262/262 [00:03<00:00, 73.69it/s]\n",
      "Epoch [93/200], Loss: 0.1365: 100%|██████████| 262/262 [00:03<00:00, 70.69it/s]\n",
      "Epoch [94/200], Loss: 0.1852: 100%|██████████| 262/262 [00:03<00:00, 71.30it/s]\n",
      "Epoch [95/200], Loss: 0.1591: 100%|██████████| 262/262 [00:03<00:00, 73.74it/s]\n",
      "Epoch [96/200], Loss: 0.1420: 100%|██████████| 262/262 [00:03<00:00, 74.20it/s]\n",
      "Epoch [97/200], Loss: 0.1831: 100%|██████████| 262/262 [00:03<00:00, 72.94it/s]\n",
      "Epoch [98/200], Loss: 0.1562: 100%|██████████| 262/262 [00:03<00:00, 70.47it/s]\n",
      "Epoch [99/200], Loss: 0.1416: 100%|██████████| 262/262 [00:03<00:00, 73.31it/s]\n",
      "Epoch [100/200], Loss: 0.1741: 100%|██████████| 262/262 [00:03<00:00, 75.55it/s]\n",
      "Epoch [101/200], Loss: 0.1188: 100%|██████████| 262/262 [00:03<00:00, 76.02it/s]\n",
      "Epoch [102/200], Loss: 0.1674: 100%|██████████| 262/262 [00:03<00:00, 71.18it/s]\n",
      "Epoch [103/200], Loss: 0.1343: 100%|██████████| 262/262 [00:03<00:00, 71.78it/s]\n",
      "Epoch [104/200], Loss: 0.1523: 100%|██████████| 262/262 [00:03<00:00, 73.18it/s]\n",
      "Epoch [105/200], Loss: 0.1400: 100%|██████████| 262/262 [00:03<00:00, 77.51it/s]\n",
      "Epoch [106/200], Loss: 0.1523: 100%|██████████| 262/262 [00:03<00:00, 80.05it/s]\n",
      "Epoch [107/200], Loss: 0.1608: 100%|██████████| 262/262 [00:03<00:00, 81.58it/s]\n",
      "Epoch [108/200], Loss: 0.1549: 100%|██████████| 262/262 [00:03<00:00, 80.92it/s]\n",
      "Epoch [109/200], Loss: 0.1636: 100%|██████████| 262/262 [00:03<00:00, 78.52it/s]\n",
      "Epoch [110/200], Loss: 0.1529: 100%|██████████| 262/262 [00:03<00:00, 78.02it/s]\n",
      "Epoch [111/200], Loss: 0.1599: 100%|██████████| 262/262 [00:03<00:00, 78.09it/s]\n",
      "Epoch [112/200], Loss: 0.1251: 100%|██████████| 262/262 [00:03<00:00, 80.02it/s]\n",
      "Epoch [113/200], Loss: 0.1595: 100%|██████████| 262/262 [00:03<00:00, 78.44it/s]\n",
      "Epoch [114/200], Loss: 0.1571: 100%|██████████| 262/262 [00:03<00:00, 77.70it/s]\n",
      "Epoch [115/200], Loss: 0.1664: 100%|██████████| 262/262 [00:03<00:00, 75.20it/s]\n",
      "Epoch [116/200], Loss: 0.1515: 100%|██████████| 262/262 [00:03<00:00, 73.50it/s]\n",
      "Epoch [117/200], Loss: 0.1486: 100%|██████████| 262/262 [00:03<00:00, 70.57it/s]\n",
      "Epoch [118/200], Loss: 0.1340: 100%|██████████| 262/262 [00:03<00:00, 73.03it/s]\n",
      "Epoch [119/200], Loss: 0.1358: 100%|██████████| 262/262 [00:03<00:00, 76.50it/s]\n",
      "Epoch [120/200], Loss: 0.1336: 100%|██████████| 262/262 [00:03<00:00, 75.41it/s]\n",
      "Epoch [121/200], Loss: 0.1407: 100%|██████████| 262/262 [00:03<00:00, 71.97it/s]\n",
      "Epoch [122/200], Loss: 0.0937: 100%|██████████| 262/262 [00:03<00:00, 71.58it/s]\n",
      "Epoch [123/200], Loss: 0.1798: 100%|██████████| 262/262 [00:03<00:00, 72.37it/s]\n",
      "Epoch [124/200], Loss: 0.1786: 100%|██████████| 262/262 [00:03<00:00, 74.63it/s]\n",
      "Epoch [125/200], Loss: 0.1488: 100%|██████████| 262/262 [00:03<00:00, 75.63it/s]\n",
      "Epoch [126/200], Loss: 0.1210: 100%|██████████| 262/262 [00:03<00:00, 73.10it/s]\n",
      "Epoch [127/200], Loss: 0.1527: 100%|██████████| 262/262 [00:03<00:00, 70.90it/s]\n",
      "Epoch [128/200], Loss: 0.1655: 100%|██████████| 262/262 [00:03<00:00, 73.41it/s]\n",
      "Epoch [129/200], Loss: 0.1309: 100%|██████████| 262/262 [00:03<00:00, 76.26it/s]\n",
      "Epoch [130/200], Loss: 0.1496: 100%|██████████| 262/262 [00:03<00:00, 74.86it/s]\n",
      "Epoch [131/200], Loss: 0.1331: 100%|██████████| 262/262 [00:03<00:00, 73.74it/s]\n",
      "Epoch [132/200], Loss: 0.1508: 100%|██████████| 262/262 [00:03<00:00, 71.47it/s]\n",
      "Epoch [133/200], Loss: 0.1529: 100%|██████████| 262/262 [00:03<00:00, 73.59it/s]\n",
      "Epoch [134/200], Loss: 0.1280: 100%|██████████| 262/262 [00:03<00:00, 75.35it/s]\n",
      "Epoch [135/200], Loss: 0.1375: 100%|██████████| 262/262 [00:03<00:00, 74.28it/s]\n",
      "Epoch [136/200], Loss: 0.1504: 100%|██████████| 262/262 [00:03<00:00, 70.91it/s]\n",
      "Epoch [137/200], Loss: 0.1882: 100%|██████████| 262/262 [00:03<00:00, 70.00it/s]\n",
      "Epoch [138/200], Loss: 0.1238: 100%|██████████| 262/262 [00:03<00:00, 73.02it/s]\n",
      "Epoch [139/200], Loss: 0.1684: 100%|██████████| 262/262 [00:03<00:00, 75.64it/s]\n",
      "Epoch [140/200], Loss: 0.1483: 100%|██████████| 262/262 [00:03<00:00, 79.72it/s]\n",
      "Epoch [141/200], Loss: 0.1435: 100%|██████████| 262/262 [00:03<00:00, 80.83it/s]\n",
      "Epoch [142/200], Loss: 0.1991: 100%|██████████| 262/262 [00:03<00:00, 80.35it/s]\n",
      "Epoch [143/200], Loss: 0.1195: 100%|██████████| 262/262 [00:03<00:00, 80.62it/s]\n",
      "Epoch [144/200], Loss: 0.1440: 100%|██████████| 262/262 [00:03<00:00, 81.04it/s]\n",
      "Epoch [145/200], Loss: 0.1669: 100%|██████████| 262/262 [00:03<00:00, 78.98it/s]\n",
      "Epoch [146/200], Loss: 0.2097: 100%|██████████| 262/262 [00:03<00:00, 76.89it/s]\n",
      "Epoch [147/200], Loss: 0.1247: 100%|██████████| 262/262 [00:03<00:00, 78.23it/s]\n",
      "Epoch [148/200], Loss: 0.1749: 100%|██████████| 262/262 [00:03<00:00, 73.80it/s]\n",
      "Epoch [149/200], Loss: 0.1340: 100%|██████████| 262/262 [00:03<00:00, 77.14it/s]\n",
      "Epoch [150/200], Loss: 0.1326: 100%|██████████| 262/262 [00:03<00:00, 75.54it/s]\n",
      "Epoch [151/200], Loss: 0.1347: 100%|██████████| 262/262 [00:03<00:00, 71.58it/s]\n",
      "Epoch [152/200], Loss: 0.1482: 100%|██████████| 262/262 [00:03<00:00, 72.04it/s]\n",
      "Epoch [153/200], Loss: 0.1250: 100%|██████████| 262/262 [00:03<00:00, 74.42it/s]\n",
      "Epoch [154/200], Loss: 0.1500: 100%|██████████| 262/262 [00:03<00:00, 74.69it/s]\n",
      "Epoch [155/200], Loss: 0.1915: 100%|██████████| 262/262 [00:03<00:00, 72.31it/s]\n",
      "Epoch [156/200], Loss: 0.1406: 100%|██████████| 262/262 [00:03<00:00, 71.26it/s]\n",
      "Epoch [157/200], Loss: 0.1154: 100%|██████████| 262/262 [00:03<00:00, 73.62it/s]\n",
      "Epoch [158/200], Loss: 0.1441: 100%|██████████| 262/262 [00:03<00:00, 73.69it/s]\n",
      "Epoch [159/200], Loss: 0.1297: 100%|██████████| 262/262 [00:03<00:00, 75.10it/s]\n",
      "Epoch [160/200], Loss: 0.1504: 100%|██████████| 262/262 [00:03<00:00, 71.33it/s]\n",
      "Epoch [161/200], Loss: 0.1445: 100%|██████████| 262/262 [00:03<00:00, 71.99it/s]\n",
      "Epoch [162/200], Loss: 0.1289: 100%|██████████| 262/262 [00:03<00:00, 73.47it/s]\n",
      "Epoch [163/200], Loss: 0.1472: 100%|██████████| 262/262 [00:03<00:00, 77.81it/s]\n",
      "Epoch [164/200], Loss: 0.1546: 100%|██████████| 262/262 [00:03<00:00, 75.41it/s]\n",
      "Epoch [165/200], Loss: 0.1484: 100%|██████████| 262/262 [00:03<00:00, 74.27it/s]\n",
      "Epoch [166/200], Loss: 0.1490: 100%|██████████| 262/262 [00:03<00:00, 71.97it/s]\n",
      "Epoch [167/200], Loss: 0.1469: 100%|██████████| 262/262 [00:03<00:00, 74.21it/s]\n",
      "Epoch [168/200], Loss: 0.1485: 100%|██████████| 262/262 [00:03<00:00, 75.84it/s]\n",
      "Epoch [169/200], Loss: 0.1283: 100%|██████████| 262/262 [00:03<00:00, 74.97it/s]\n",
      "Epoch [170/200], Loss: 0.1657: 100%|██████████| 262/262 [00:03<00:00, 73.07it/s]\n",
      "Epoch [171/200], Loss: 0.1488: 100%|██████████| 262/262 [00:03<00:00, 72.61it/s]\n",
      "Epoch [172/200], Loss: 0.1437: 100%|██████████| 262/262 [00:03<00:00, 72.70it/s]\n",
      "Epoch [173/200], Loss: 0.1373: 100%|██████████| 262/262 [00:03<00:00, 75.68it/s]\n",
      "Epoch [174/200], Loss: 0.1190: 100%|██████████| 262/262 [00:03<00:00, 73.56it/s]\n",
      "Epoch [175/200], Loss: 0.0946: 100%|██████████| 262/262 [00:03<00:00, 76.75it/s]\n",
      "Epoch [176/200], Loss: 0.1589: 100%|██████████| 262/262 [00:03<00:00, 78.18it/s]\n",
      "Epoch [177/200], Loss: 0.1110: 100%|██████████| 262/262 [00:03<00:00, 78.58it/s]\n",
      "Epoch [178/200], Loss: 0.1334: 100%|██████████| 262/262 [00:03<00:00, 79.30it/s]\n",
      "Epoch [179/200], Loss: 0.1356: 100%|██████████| 262/262 [00:03<00:00, 77.18it/s]\n",
      "Epoch [180/200], Loss: 0.1384: 100%|██████████| 262/262 [00:03<00:00, 76.02it/s]\n",
      "Epoch [181/200], Loss: 0.1582: 100%|██████████| 262/262 [00:03<00:00, 78.58it/s]\n",
      "Epoch [182/200], Loss: 0.1422: 100%|██████████| 262/262 [00:03<00:00, 70.45it/s]\n",
      "Epoch [183/200], Loss: 0.1930: 100%|██████████| 262/262 [00:03<00:00, 74.59it/s]\n",
      "Epoch [184/200], Loss: 0.1590: 100%|██████████| 262/262 [00:03<00:00, 72.72it/s]\n",
      "Epoch [185/200], Loss: 0.1919: 100%|██████████| 262/262 [00:03<00:00, 71.80it/s]\n",
      "Epoch [186/200], Loss: 0.1245: 100%|██████████| 262/262 [00:03<00:00, 73.29it/s]\n",
      "Epoch [187/200], Loss: 0.1842: 100%|██████████| 262/262 [00:03<00:00, 76.73it/s]\n",
      "Epoch [188/200], Loss: 0.1481: 100%|██████████| 262/262 [00:03<00:00, 73.32it/s]\n",
      "Epoch [189/200], Loss: 0.1156: 100%|██████████| 262/262 [00:03<00:00, 72.01it/s]\n",
      "Epoch [190/200], Loss: 0.1306: 100%|██████████| 262/262 [00:03<00:00, 72.17it/s]\n",
      "Epoch [191/200], Loss: 0.1695: 100%|██████████| 262/262 [00:03<00:00, 71.62it/s]\n",
      "Epoch [192/200], Loss: 0.1343: 100%|██████████| 262/262 [00:03<00:00, 73.98it/s]\n",
      "Epoch [193/200], Loss: 0.1384: 100%|██████████| 262/262 [00:03<00:00, 75.18it/s]\n",
      "Epoch [194/200], Loss: 0.1266: 100%|██████████| 262/262 [00:03<00:00, 70.15it/s]\n",
      "Epoch [195/200], Loss: 0.1032: 100%|██████████| 262/262 [00:03<00:00, 71.02it/s]\n",
      "Epoch [196/200], Loss: 0.1808: 100%|██████████| 262/262 [00:03<00:00, 72.61it/s]\n",
      "Epoch [197/200], Loss: 0.1497: 100%|██████████| 262/262 [00:03<00:00, 74.50it/s]\n",
      "Epoch [198/200], Loss: 0.1263: 100%|██████████| 262/262 [00:03<00:00, 72.59it/s]\n",
      "Epoch [199/200], Loss: 0.1098: 100%|██████████| 262/262 [00:03<00:00, 72.05it/s]\n",
      "Epoch [200/200], Loss: 0.1061: 100%|██████████| 262/262 [00:03<00:00, 70.77it/s]\n"
     ]
    }
   ],
   "source": [
    "# model = Transformer(\n",
    "#     src_vocab_size=len(word2idx_src),\n",
    "#     tgt_vocab_size=len(word2idx_tgt),\n",
    "#     src_pad_idx=word2idx_src['<PAD>'],\n",
    "#     tgt_pad_idx=word2idx_tgt['<PAD>'],\n",
    "#     emb_dim=EMB_DIM,\n",
    "#     num_layers=N_LAYERS,\n",
    "#     num_heads=N_HEADS,\n",
    "#     forward_dim=FORWARD_DIM,\n",
    "#     dropout=DROPOUT,\n",
    "#     max_len=MAX_LEN,\n",
    "# ).to(device)\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=word2idx_tgt['<PAD>'])\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 200\n",
    "losses = []\n",
    "accuraacy = []\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for step, (src, tgt) in (pbar := tqdm(enumerate(train_loader), total=len(train_loader))):\n",
    "        src, tgt = src.to(device), tgt.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # output = model(src, tgt)\n",
    "        output = model(src, tgt[:, :-1])\n",
    "        output_dim = output.shape[-1]\n",
    "\n",
    "        output = output.contiguous().view(-1, output_dim)\n",
    "        tgt = tgt[:, 1:].contiguous().view(-1)\n",
    "\n",
    "        loss = criterion(output, tgt)\n",
    "        loss.backward()\n",
    "\n",
    "        # Gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), GRAD_CLIP)\n",
    "        pbar.set_description(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss:.4f}')\n",
    "\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    avg_epoch_loss = epoch_loss / len(train_loader)\n",
    "    losses.append(avg_epoch_loss)\n",
    "checkpoint_path = f\"transformer_exp1_200.pth\"\n",
    "torch.save(\n",
    "    {'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "}, checkpoint_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reverse the word-to-index mapping\n",
    "idx2word_src = {idx: w for w, idx in word2idx_src.items()}\n",
    "idx2word_tgt = {idx: w for w, idx in word2idx_tgt.items()}\n",
    "\n",
    "def decode_indices(indices, idx2word):\n",
    "    return ' '.join(idx2word[idx] for idx in indices if idx in idx2word and idx != word2idx_src['<PAD>'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TOKEN LEVEL ACC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Batch inference\n",
    "# TODO: Token level accuracy\n",
    "# TODO: Sequence level accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])\n",
      "tensor([[ 6,  3, 14, 13, 10,  6,  3,  1,  7,  0]], device='cuda:0')\n",
      "ground t: tensor([[3, 6, 6, 6, 6, 6, 6, 7, 7, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0')\n",
      "predicted: tensor([[3, 6, 6, 6, 6, 6, 6, 7, 7]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\magnu\\AppData\\Local\\Temp\\ipykernel_13572\\1982701368.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckp = torch.load(checkpoint_path)\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = f\"transformer_exp1_200.pth\"\n",
    "ckp = torch.load(checkpoint_path)\n",
    "model.load_state_dict(ckp['model_state_dict'])\n",
    "total_tokens = 0\n",
    "correct_tokens = 0\n",
    "\n",
    "def inference(input_seq: str):\n",
    "    model.eval()\n",
    "    pass\n",
    "\n",
    "model.eval()\n",
    "\n",
    "src, true_tgt = next(iter(test_loader))\n",
    "print(src.shape)\n",
    "src = src[0].unsqueeze(0).to(device)\n",
    "true_tgt = true_tgt[0].unsqueeze(0).to(device)\n",
    "# src, true_tgt = next(iter(test_loader))[0][0].unsqueeze(0).to(device)\n",
    "\n",
    "print(src)\n",
    "tgt = torch.tensor([[word2idx_tgt['<SOS>']]]).to(device)\n",
    "# tgt = torch.tensor([[word2idx_tgt['<SOS>']]]).to(device)\n",
    "\n",
    "# print(f'tgt {tgt.shape}')\n",
    "# print(f'src {src.shape}')\n",
    "iterations = 20\n",
    "pred_sequence = [tgt.item()]\n",
    "# print(pred_sequence)\n",
    "\n",
    "for i in range(iterations):\n",
    "    with torch.no_grad():\n",
    "        # print(tgt)\n",
    "        output = model.forward(src, tgt)\n",
    "        predictions = nn.functional.softmax(output[:, -1, :], dim=-1)\n",
    "        # print(\"argmax:\", predictions.argmax(-1).shape)\n",
    "        next_token = predictions.argmax(-1).item()\n",
    "\n",
    "        if next_token == word2idx_tgt['<EOS>']:\n",
    "            break\n",
    "\n",
    "        # next_token_tensor = torch.tensor([[next_token]]).to(device)\n",
    "        # tgt = torch.cat([tgt, next_token_tensor], dim=1)\n",
    "        \n",
    "        pred_sequence.append(next_token)\n",
    "        tgt = torch.tensor(pred_sequence).unsqueeze(0).to(device)\n",
    "\n",
    "        \n",
    "        # print(tgt.shape)\n",
    "        # print(\"tgt\", tgt)\n",
    "\n",
    "print(f'ground t: {true_tgt}')\n",
    "print(f'predicted: {tgt}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BATCH INFERENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10]) torch.Size([64, 32])\n",
      "tensor([ 6,  3, 14, 13, 10,  6,  3,  1,  7,  0], device='cuda:0')\n",
      "torch.Size([1, 1])\n",
      "ground t: tensor([[3, 6, 6, 6, 6, 6, 6, 7, 7, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0')\n",
      "predicted: tensor([[3, 6, 6, 6, 6, 6, 6, 7, 7]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\magnu\\AppData\\Local\\Temp\\ipykernel_13572\\1743596659.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckp = torch.load(checkpoint_path)\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = f\"transformer_exp1_200.pth\"\n",
    "ckp = torch.load(checkpoint_path)\n",
    "model.load_state_dict(ckp['model_state_dict'])\n",
    "total_tokens = 0\n",
    "correct_tokens = 0\n",
    "\n",
    "src, tgt = next(iter(test_loader))\n",
    "print(src.shape, tgt.shape)\n",
    "\n",
    "\n",
    "for src_batch, tgt_batch in test_loader:\n",
    "    for src, tgt in zip(src_batch, tgt_batch):    \n",
    "        print(src)\n",
    "        # \n",
    "        src = src.unsqueeze(0).to(device)\n",
    "        true_tgt = tgt.unsqueeze(0).to(device)\n",
    "        tgt = torch.tensor([[word2idx_tgt['<SOS>']]]).to(device)\n",
    "        \n",
    "        iterations = MAX_LEN\n",
    "        pred_sequence = [tgt.item()]\n",
    "        print(tgt.shape)\n",
    "        # print(src.shape, true_tgt.shape)\n",
    "\n",
    "        for i in range(iterations):\n",
    "            with torch.no_grad():\n",
    "                output = model.forward(src, tgt)\n",
    "                predictions = nn.functional.softmax(output[:, -1, :], dim=-1)\n",
    "                next_token = predictions.argmax(-1).item()\n",
    "\n",
    "                # Stop if end of sequence\n",
    "                if next_token == word2idx_tgt['<EOS>']:\n",
    "                    break\n",
    "\n",
    "                pred_sequence.append(next_token)\n",
    "                tgt = torch.tensor(pred_sequence).unsqueeze(0).to(device)\n",
    "\n",
    "        print(f'ground t: {true_tgt}')\n",
    "        print(f'predicted: {tgt}')\n",
    "        \n",
    "        break\n",
    "    break\n",
    "        # true_tgt = tgt.to(device)\n",
    "        # print(f\"True tgt shape: {true_tgt.shape}\")\n",
    "        \n",
    "        # tgt = (torch.ones(src.shape[0], 1)*word2idx_tgt['<SOS>']).to(device) #maybe change to int\n",
    "        # print(f\"tgt shape: {tgt.shape}, First tgt: {tgt[0]}\")\n",
    "\n",
    "        \n",
    "        # #list with 64 lists inside\n",
    "        # pred_sequences = [[word2idx_tgt['<SOS>']] for _ in range(src.shape[0])]\n",
    "        # print(len(pred_sequences))\n",
    "\n",
    "    # Compute outputs\n",
    "    # with torch.no_grad():\n",
    "\n",
    "\n",
    "    # print(src.shape)\n",
    "\n",
    "    # true_tgt = true_tgt[0].unsqueeze(0).to(device)\n",
    "    # # src, true_tgt = next(iter(test_loader))[0][0].unsqueeze(0).to(device)\n",
    "\n",
    "    # print(src)\n",
    "    # tgt = torch.tensor([[word2idx_tgt['<SOS>']]]).to(device)\n",
    "    # # tgt = torch.tensor([[word2idx_tgt['<SOS>']]]).to(device)\n",
    "\n",
    "    # # print(f'tgt {tgt.shape}')\n",
    "    # # print(f'src {src.shape}')\n",
    "    # iterations = 20\n",
    "    # pred_sequence = [tgt.item()]\n",
    "    # # print(pred_sequence)\n",
    "\n",
    "    # for i in range(iterations):\n",
    "    #     with torch.no_grad():\n",
    "    #         # print(tgt)\n",
    "    #         output = model.forward(src, tgt)\n",
    "    #         predictions = nn.functional.softmax(output[:, -1, :], dim=-1)\n",
    "    #         # print(\"argmax:\", predictions.argmax(-1).shape)\n",
    "    #         next_token = predictions.argmax(-1).item()\n",
    "\n",
    "    #         if next_token == word2idx_tgt['<EOS>']:\n",
    "    #             break\n",
    "\n",
    "    #         # next_token_tensor = torch.tensor([[next_token]]).to(device)\n",
    "    #         # tgt = torch.cat([tgt, next_token_tensor], dim=1)\n",
    "            \n",
    "    #         pred_sequence.append(next_token)\n",
    "    #         tgt = torch.tensor(pred_sequence).unsqueeze(0).to(device)\n",
    "    #         # print(tgt.shape)\n",
    "    #         # print(\"tgt\", tgt)\n",
    "\n",
    "    # print(f'ground t: {true_tgt}')\n",
    "    # p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
